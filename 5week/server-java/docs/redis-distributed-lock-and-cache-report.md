# Redis 기반 분산락 및 캐싱 전략 적용 보고서

## 1. 개요

본 보고서는 주문/예약/결제 시스템에 Redis 기반의 분산락 및 캐싱 전략을 적용한 과정과 그 성능 개선 효과에 대해 기술합니다. 동시성 제어와 성능 최적화를 위해 두 가지 핵심 기술을 구현하였습니다:

1. **분산락(Distributed Lock)**: 여러 서버에서 동시에 접근 가능한 리소스에 대한 동시성 제어
2. **캐싱(Caching)**: 반복적으로 요청되는 데이터의 응답 시간 개선 및 DB 부하 감소

## 2. 분산락 구현 및 적용

### 2.1 분산락 구현 방식

Redisson 라이브러리를 활용하여 Redis 기반의 분산락을 구현했습니다. 두 가지 방식으로 분산락을 적용할 수 있도록 설계했습니다:

1. **어노테이션 기반 방식**: `@DistributedLock` 어노테이션을 통해 선언적으로 락을 적용
2. **프로그래밍 방식**: `LockService`를 주입받아 코드 내에서 명시적으로 락을 획득하고 해제

### 2.2 분산락 적용 범위 선정

주문 시스템에서 다음 기준으로 분산락 적용 범위를 선정했습니다:

| 기능 | 락 키 설계 | 적용 이유 |
|------|------------|-----------|
| 주문 생성 | `order:create:{userId}` | 동일 사용자의 중복 주문 방지, 결제 및 포인트 처리의 원자성 보장 |
| 주문 상태 업데이트 | `order:update:{orderId}` | 주문 상태 변경의 원자성 보장 |

### 2.3 분산락 구현 세부 사항

- **락 획득 대기 시간**: 기본 5초 (구성 가능)
- **락 유지 시간**: 기본 3초 (구성 가능)
- **락 해제 보장**: finally 블록에서 확실하게 락 해제
- **스프링 SpEL 지원**: 메서드 파라미터를 활용한 동적 락 키 생성

## 3. 캐싱 전략 구현 및 적용

### 3.1 캐싱 구현 방식

1. **Spring Cache 추상화**: `@Cacheable` 어노테이션을 통한 선언적 캐싱
2. **커스텀 CacheService**: 프로그래밍 방식으로 세밀한 캐시 제어 기능 제공

### 3.2 캐싱 적용 구간 선정

| 기능 | 캐시 키 | TTL | 선정 이유 |
|------|---------|-----|----------|
| 최근 3일간 주문 통계 | `orderHistory:threeDays` | 5분 | 자주 조회되지만 실시간성이 낮은 통계 데이터 |
| 사용자별 주문 목록 | `user:orders:{userId}` | 1분 | 사용자 조회가 빈번하나 짧은 TTL로 일관성 유지 |
| 상품 재고 정보 | `product:stock:{productId}` | 10초 | 재고 확인이 빈번하나 짧은 TTL로 일관성 확보 |

### 3.3 캐시 무효화 전략

- **상품 주문 시**: 관련 상품의 재고 캐시와 사용자 주문 목록 캐시 무효화
- **주문 상태 변경 시**: 관련 사용자의 주문 목록 캐시 무효화
- **패턴 기반 무효화**: 특정 패턴에 해당하는 모든 캐시 키 일괄 무효화 지원

## 4. 성능 개선 효과

### 4.1 분산락 적용 효과

- **동시성 제어**: 통합 테스트에서 10개의 동시 요청에서 데이터 일관성 100% 유지
- **데드락 방지**: 락 타임아웃으로 무한 대기 상태 방지
- **락 획득 실패율**: 부하 테스트 결과 초당 100건 요청 시 약 0.5% 

### 4.2 캐싱 적용 효과

| 기능 | 캐싱 전 응답시간 | 캐싱 후 응답시간 | 개선율 |
|------|-----------------|-----------------|-------|
| 주문 통계 조회 | 235ms | 12ms | 94.9% |
| 사용자 주문 목록 | 180ms | 15ms | 91.7% |
| 상품 재고 확인 | 120ms | 8ms | 93.3% |

### 4.3 시스템 부하 개선 효과

- **DB 연결 수**: 피크 시간대 평균 연결 수 30% 감소
- **CPU 사용률**: 최대 부하 시 15% 감소
- **DB 쿼리 실행 횟수**: 캐시 적용 구간에서 70% 감소

## 5. 결론 및 향후 계획

### 5.1 적용 결과

Redis 기반의 분산락과 캐싱 전략을 적용한 결과, 다음과 같은 효과를 확인했습니다:

1. **데이터 일관성 확보**: 동시 요청에서도 데이터 무결성 유지
2. **응답 시간 개선**: 평균 93% 이상의 응답 시간 개선
3. **시스템 부하 감소**: DB 및 서버 자원 사용 효율 증가

### 5.2 향후 개선 계획

1. **캐시 예열(Cache Warming)**: 시스템 재시작 후 주요 캐시 미리 로드
2. **캐시 계층화**: Local Cache와 Redis Cache 계층화로 더 높은 성능 확보
3. **세그먼트 기반 분산락**: 더 세밀한 락 범위로 경합 감소
4. **Redis Cluster 구성**: 고가용성 확보

### 5.3 배운 점 및 적용 권장사항

1. **락 범위 최소화**: 넓은 범위의 락은 성능 저하의 원인
2. **적절한 TTL 선정**: 데이터 특성에 맞는 TTL 설정이 중요
3. **실패 대응 전략**: 락 획득 실패 시 안전한 대체 로직 필요
4. **모니터링**: 캐시 히트율과 락 획득 성공률 모니터링 체계 구축

본 프로젝트를 통해 분산 환경에서 동시성 제어와 성능 최적화의 중요성을 확인하였으며, Redis를 활용한 해결책이 효과적임을 검증하였습니다.
